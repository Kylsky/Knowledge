# I/O模型

参考：https://www.jianshu.com/p/5257b540c3e5

I/O模型主要分为BIO、NIO、多路复用IO以及AIO，在介绍这四种I/O模型之前，先回顾一下什么是同步和异步，以及什么是阻塞和非阻塞

## 同步&异步

同步和异步关注点在于**线程调用方法之后是否需要立即返回结果**，若立即得到结果，则表示同步，否则为异步。

**举一个例子**，老李在家烧热水，当老李按下开关后，水壶开始烧水，并在几分钟后烧开并通知老李，这个过程中老李并不需要等在水壶旁边等待第一时间水烧开，可以**做别的事**，这便是**异步**。但是若老李需要用烧好的热水煮泡面，那么他就需要等待热水稍好才能做接下来的事，这便是**同步**。



## 阻塞&非阻塞

阻塞与非阻塞的关注点在于**线程等待结果时的状态**。

还是举老李烧热水的例子，现在老李需要第一时间使用热水煮泡面，那么他将有两种选择：1.什么都不做等着水烧开；2.一边等水烧开一边去看电视。则前者是阻塞的，即老李等待结果时什么都不做。后者是非阻塞的，即老李不需要一直干等着。



简单地回顾了以下同步、异步和阻塞、非阻塞，接下来看看四种I/O模型：

## BIO

BIO(Blocking I/O)，即同步阻塞I/O。图示为BIO的I/O模型：

![img](http://kylescloud.top/site/pic/BIO.png)

来看看使用BIO模型时的整体执行流程：

1.程序调用`socket.read()`，这个方法会调用一个`native read()`方法，所以最终是由 OS执行read
2.OS得到read指令，命令网卡读取数据。
3.网卡读取数据完成后，将数据传递给内核。
4.内核把读取的数据拷贝的用户空间。
5.程序解除阻塞，完成read函数。



当一个线程获取了CPU的资源使其调用read时，另外一个线程就**被阻塞**住了，**直到第一个线程返回结果**第二个线程才会执行，可以发现这样的**效率实在不高**。



## 二、NIO

NIO(Non-blocking I/O)，同步非阻塞I/O，要说NIO相比BIO的优越之处就在于“非阻塞”，即线程在等待结果时不再将其他线程阻塞，先看看NIO模型：

![img](http://kylescloud.top/site/pic/NIO.png)

当一个进程或一个线程多次调用socket.read方法时，不再阻塞，而是通过轮询调用系统内核，直到操作系统返回结果。这直接减少了线程之间多余的阻塞等待时间。

虽然NIO比之BIO好像厉害了不少，但是它仍然存在问题，这就是——用户态内核态的切换。因为NIO的轮询是通过反复调用socket.read方法的，即轮询发生在用户态，所以**n次轮询**就需要发生**n次用户态和内核态的切换**，这样的效率还是不够理想，于是多路复用I/O出现了。



## 三、多路复用I/O

多路复用I/O(IO Multiplex),看一下多路复用I/O的简单模型：

![img](http://kylescloud.top/site/pic/IOMultiplex.jpg)

倘若目前有1000个连接连到操作系统内核，线程并不像NIO那样“无脑”地向操作系统轮询所有的fd(file dwscriptor,文件描述符)，而是先询问一下哪些fd已经有数据可以进行处理了，随后再将需要处理的进行轮询。这在**一定程度上降低了用户态内核态的切换，不过还是治标不治本**。有什么解决方法呢？

来看看Linux系统下通过epoll实现的多路复用是如何解决问题的：

![img](http://kylescloud.top/site/pic/LinuxEpoll.jpg)

epoll中使用mmap(内存映射)创建了用户态和内核态的共享空间，当线程(用户态)通过epoll-create创建需要监听的fd的句柄并传递给内核，内核通过epoll-ctl注册这些句柄到共享空间的红黑树中，并调用epoll-wait等待数据产生，并传输到共享空间的链表中，并通知线程处理任务，这样能有效地提高运行效率。



## 四、AIO

AIO(Asynchronous I/O),Asynchronous IO调用中是真正的无阻塞，其他IO model中多少会有点阻塞。程序发起read操作之后，立刻就可以开始去做其它的事。而在内核角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。