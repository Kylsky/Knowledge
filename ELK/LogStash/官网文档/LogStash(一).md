# Logstash(一)介绍

Logstash是一个具有实时流水线功能的开源数据收集引擎。Logstash可以动态地统一来自不同来源的数据，并将数据规范化并发送到指定的目的地。为各种高级下游分析和可视化用例清理和泛化所有数据。虽然Logstash最初推动了日志收集方面的创新，但它的功能远远超出了用例的范围。任何类型的事件都可以通过大量的输入、筛选和输出插件进行丰富和转换

## 一、LogStash功能

1. 嵌入elasticsearch及更多平台
2. 可插入的管道架构
3. 社区可扩展和开发人员友好的插件生态系统

![img](https://www.elastic.co/guide/en/logstash/current/static/images/logstash.png)



## 二、Logstash与数据

### Logs and Metrics

1. 处理所有类型的日志数据
2. 与Filebeat互补的安全日志转发功能
3. 通过TCP和UDP从Ganglia、collectd、NetFlow、JMX和许多其他基础设施和应用程序平台收集指标



### 网络

1. 将HTTP请求转换为事件

2. 通过按需轮询HTTP端点来创建事件



### 数据存储与流

1. 更好地理解来自任何具有JDBC接口的关系数据库或NoSQL存储的数据

2. 统一来自消息传递队列的不同数据流，如Apache Kafka、RabbitMQ和Amazon SQS



##  三、能力扩展

数据越好，知识就越丰富。在摄入数据期间进行清理和转换，以便在索引或输出时立即获得近乎实时的信息。Logstash提供了许多即时可用的聚合和突变，以及模式匹配、地理映射和动态查找功能。

1. Grok是Logstash过滤器的主要组成部分，广泛用于从非结构化数据派生出结构。提供了大量的集成模式，旨在帮助快速解析web、系统、网络和其他类型的事件格式。
2. 通过从IP地址解析地理坐标、规范化日期复杂性、简化键-值对和CSV数据、指纹(匿名化)敏感信息以及使用本地查找或弹性搜索查询进一步丰富数据来扩展您的视野。
3. 编解码器通常用于简化对JSON和多行事件等常见事件结构的处理。